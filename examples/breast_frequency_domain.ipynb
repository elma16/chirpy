{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# %cd /content/drive/MyDrive/chirpy\n",
    "# !pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b43a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.io import savemat\n",
    "\n",
    "from chirpy.io import load_mat, save_results\n",
    "from chirpy.geometry import TransducerArray2D, ImageGrid2D\n",
    "from chirpy.data import AcquisitionData, ImageData\n",
    "from chirpy.processors import (\n",
    "    GaussianTimeWindow,\n",
    "    DTFT,\n",
    "    PhaseScreenCorrection,\n",
    "    DownSample,\n",
    "    AcceptanceMask,\n",
    "    MagnitudeOutlierFilter,\n",
    "    Pipeline,\n",
    ")\n",
    "from chirpy.optimization.function.least_squares import NonlinearLS\n",
    "from chirpy.optimization.algorithm.cg import CG\n",
    "from chirpy.optimization.operator.helmholtz import HelmholtzOperator\n",
    "from chirpy.optimization.gradient.adjoint_helmholtz import HelmholtzAdjointGrad\n",
    "\n",
    "# from UFWI.utils.InversionVisualizer import InversionVisualizer  # Visualization wrapper\n",
    "from chirpy.utils.visulizer_multi_mode import Visualizer\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (1) Load raw k-Wave data and construct AcquisitionData and ImageGeometry\n",
    "# ------------------------------------------------------------------------------\n",
    "raw_mat = Path(\"SampleData/kWave_BreastCT.mat\")\n",
    "raw = load_mat(raw_mat)\n",
    "\n",
    "pos = raw[\"transducerPositionsXY\"]  # (2, N)\n",
    "N = pos.shape[1]\n",
    "ones = np.ones(N, dtype=bool)\n",
    "tx_array = TransducerArray2D(positions=pos.astype(np.float32), is_tx=ones, is_rx=ones)\n",
    "\n",
    "# Define imaging grid\n",
    "# give grid spacing and half-width to ImageGeometry and it makes grid automatically\n",
    "dxi = 0.6e-3\n",
    "xmax = 120e-3\n",
    "img_grid = ImageGrid2D(dx=dxi, xmax=xmax)\n",
    "c0 = 1540.0  # Speed of sound in water\n",
    "\n",
    "# Construct AcquisitionData\n",
    "acq_data = AcquisitionData(\n",
    "    array=raw[\"full_dataset\"].transpose(2, 1, 0),  # (Tx,Rx,T)\n",
    "    time=raw[\"time\"],  # (T,)\n",
    "    tx_array=tx_array,\n",
    "    grid=img_grid,\n",
    "    c0=c0,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (2) Define frequency list & preprocessing pipeline\n",
    "# ------------------------------------------------------------------------------\n",
    "f_sos = np.arange(0.3, 1.3, 0.05) * 1e6  # Frequencies for SoS-only stage\n",
    "f_att = np.arange(0.325, 1.325, 0.05) * 1e6  # Frequencies for attenuation stage\n",
    "freqs = np.concatenate([f_sos, f_att])  # All frequencies (Nfreq,)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    stages=[\n",
    "        GaussianTimeWindow(),\n",
    "        DTFT(freqs),\n",
    "        PhaseScreenCorrection(img_grid),\n",
    "        DownSample(step=1),\n",
    "        AcceptanceMask(delta=63),\n",
    "        MagnitudeOutlierFilter(threshold=0.99),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Apply all preprocessing to the acquisition data\n",
    "acq_data = pipe(acq_data)  # Resulting shape: (Tx, Rx, Nfreq)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (3) Prepare iteration counts for SoS/Atten per frequency\n",
    "# ------------------------------------------------------------------------------\n",
    "Tx, Rx, Nfreq = acq_data.array.shape\n",
    "n_sos = f_sos.size\n",
    "n_att = f_att.size\n",
    "assert n_sos + n_att == Nfreq\n",
    "\n",
    "# Run 3 SoS iterations for all 40 frequencies,\n",
    "# and 3 attenuation iterations for the latter 20 frequencies\n",
    "niterSoSPerFreq = np.array([3] * n_sos + [3] * n_att)\n",
    "niterAttenPerFreq = np.array([0] * n_sos + [3] * n_att)\n",
    "total_iters = int(np.sum(niterSoSPerFreq) + np.sum(niterAttenPerFreq))\n",
    "print(\n",
    "    f\"SoS iterations per frequency: {niterSoSPerFreq}, Atten iterations: {niterAttenPerFreq}\"\n",
    ")\n",
    "print(f\"Total number of iterations: {total_iters} (SoS + Atten)\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (4) Initialize complex slowness model using ImageData\n",
    "# ------------------------------------------------------------------------------\n",
    "c_init = 1480.0\n",
    "atten_init = 0.0\n",
    "\n",
    "Nxi, Nyi = img_grid.nx, img_grid.ny\n",
    "SLOW_INIT = (1.0 / c_init) + 1j * (atten_init / (2.0 * np.pi))\n",
    "slow0 = np.full((Nyi, Nxi), SLOW_INIT, dtype=np.complex128)\n",
    "slow_data = ImageData(array=slow0, grid=img_grid)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (5) Create visualizer (InversionVisualizer)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Load ground truth for comparison\n",
    "C_true = raw[\"C\"]  # (Nyi, Nxi)\n",
    "atten_true = raw[\"atten\"]  # (Nyi, Nxi)\n",
    "# viz = InversionVisualizer(img_grid.xi, img_grid.yi, C_true, atten_true)\n",
    "\n",
    "viz = Visualizer(\n",
    "    xi=img_grid.xi,\n",
    "    yi=img_grid.yi,\n",
    "    C_true=C_true,\n",
    "    atten_true=atten_true,\n",
    "    mode=\"both\",\n",
    "    baseline=1500,\n",
    "    sign_conv=-1,  # 与算子一致\n",
    "    atten_unit=\"Np/(Hz·m)\",\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (6) Loop over each frequency, use CG_Time.solve(...) in two stages\n",
    "#     \"Print time per iteration + automatic plotting\"\n",
    "# ------------------------------------------------------------------------------\n",
    "cg = CG(c1=1e-4, shrink=0.5, max_ls=20)\n",
    "\n",
    "for idx_f in range(Nfreq):\n",
    "    print(\n",
    "        f\"\\n=== Processing frequency idx_f = {idx_f}, f = {freqs[idx_f] / 1e6:.3f} MHz ===\"\n",
    "    )\n",
    "    n_sos = niterSoSPerFreq[idx_f]\n",
    "    n_att = niterAttenPerFreq[idx_f]\n",
    "\n",
    "    operator = HelmholtzOperator(\n",
    "        acq_data, idx_f, sign_conv=-1, pml_alpha=10.0, pml_size=9.0e-3\n",
    "    )\n",
    "    grad = HelmholtzAdjointGrad(\n",
    "        operator,\n",
    "        deriv_fn=lambda m, op: 8\n",
    "        * np.pi**2\n",
    "        * op.get_field(\"freq\") ** 2\n",
    "        * (op.get_field(\"PML\") / op.get_field(\"V\")),\n",
    "    )\n",
    "    fun = NonlinearLS(operator, grad_eval=grad)\n",
    "\n",
    "    # —— SoS-only stage: update only real part → mode=\"real\" ——\n",
    "    if n_sos > 0:\n",
    "        cg.solve(fun, slow_data, n_iter=n_sos, mode=\"real\", viz=viz, do_print_time=True)\n",
    "\n",
    "    # —— Atten-only stage: update only imaginary part → mode=\"imag\" ——\n",
    "    if n_att > 0:\n",
    "        cg.solve(fun, slow_data, n_iter=n_att, mode=\"imag\", viz=viz, do_print_time=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (7) Take a snapshot of the Recorder and save it under the variable name.\n",
    "# ------------------------------------------------------------------------------\n",
    "rec = cg.get_record()\n",
    "VEL_ESTIM_ITER = rec[\"vel\"]\n",
    "ATTEN_ESTIM_ITER = rec[\"atten\"]\n",
    "GRAD_IMG_ITER = rec[\"grad\"]\n",
    "SEARCH_DIR_ITER = rec[\"search\"]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# (8) Save the final result + intermediate snapshots\n",
    "# ------------------------------------------------------------------------------\n",
    "Path(\"Results\").mkdir(exist_ok=True)\n",
    "savemat(\n",
    "    \"Results/kWave_BreastCT_WaveformInversionResults.mat\",\n",
    "    {\n",
    "        \"xi\": img_grid.xi,\n",
    "        \"yi\": img_grid.yi,\n",
    "        \"fDATA\": freqs.reshape(1, -1),\n",
    "        \"niterAttenPerFreq\": niterAttenPerFreq.reshape(1, -1),\n",
    "        \"niterSoSPerFreq\": niterSoSPerFreq.reshape(1, -1),\n",
    "        \"VEL_ESTIM_ITER\": VEL_ESTIM_ITER,\n",
    "        \"ATTEN_ESTIM_ITER\": ATTEN_ESTIM_ITER,\n",
    "        \"GRAD_IMG_ITER\": GRAD_IMG_ITER,\n",
    "        \"SEARCH_DIR_ITER\": SEARCH_DIR_ITER,\n",
    "    },\n",
    "    do_compression=True,\n",
    ")\n",
    "\n",
    "print(\"Results saved to Results/kWave_BreastCT_WaveformInversionResults.mat\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
